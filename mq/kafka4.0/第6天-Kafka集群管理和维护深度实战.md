# ç¬¬6å¤©ï¼šKafka 4.0é›†ç¾¤ç®¡ç†å’Œç»´æŠ¤æ·±åº¦å®æˆ˜

## ğŸ¯ å­¦ä¹ ç›®æ ‡
- æŒæ¡Kafka 4.0 KRaftæ¨¡å¼çš„é›†ç¾¤éƒ¨ç½²å’Œç®¡ç†
- æ·±å…¥ç†è§£Kafka 4.0æ–°ä¸€ä»£æ¶ˆè´¹è€…é‡å¹³è¡¡åè®®
- æŒæ¡Kafka 4.0é›†ç¾¤æ‰©å®¹ã€ç¼©å®¹çš„æ“ä½œæµç¨‹
- å­¦ä¼šKafka 4.0ç‰ˆæœ¬å‡çº§å’Œè¿ç§»ç­–ç•¥
- æŒæ¡Kafka 4.0ä¼ä¸šçº§ç›‘æ§å’Œæ•…éšœæ’æŸ¥æŠ€èƒ½

---

## ğŸš€ Kafka 4.0æ ¸å¿ƒæ–°ç‰¹æ€§

### 1. KRaftæ¨¡å¼ï¼ˆå»ZookeeperåŒ–ï¼‰

#### 1.1 KRaftæ¶æ„ä¼˜åŠ¿
```yaml
# Kafka 4.0 KRaftæ¨¡å¼æ¶æ„
kraft_architecture:
  controller_nodes: 3ä¸ªæ§åˆ¶å™¨èŠ‚ç‚¹
  broker_nodes: å¤šä¸ªæ•°æ®èŠ‚ç‚¹
  metadata_storage: å†…ç½®å…ƒæ•°æ®å­˜å‚¨
  
# ç›¸æ¯”Zookeeperæ¨¡å¼çš„ä¼˜åŠ¿
advantages:
  - ç®€åŒ–éƒ¨ç½²ï¼šæ— éœ€é¢å¤–çš„Zookeeperé›†ç¾¤
  - æ›´å¿«å¯åŠ¨ï¼šå…ƒæ•°æ®åŠ è½½é€Ÿåº¦æå‡10å€
  - æ›´å¥½æ‰©å±•ï¼šæ”¯æŒç™¾ä¸‡çº§åˆ†åŒº
  - æ›´å¼ºä¸€è‡´æ€§ï¼šRaftåè®®ä¿è¯å¼ºä¸€è‡´æ€§
  - æ›´ä½å»¶è¿Ÿï¼šå…ƒæ•°æ®æ“ä½œå»¶è¿Ÿé™ä½50%
```

#### 1.2 KRafté›†ç¾¤é…ç½®
```properties
# kraft-controller.properties - æ§åˆ¶å™¨èŠ‚ç‚¹é…ç½®
process.roles=controller
node.id=1
controller.quorum.voters=1@controller1:9093,2@controller2:9093,3@controller3:9093
listeners=CONTROLLER://controller1:9093
inter.broker.listener.name=CONTROLLER
controller.listener.names=CONTROLLER
log.dirs=/data/kraft-controller-logs

# kraft-broker.properties - æ•°æ®èŠ‚ç‚¹é…ç½®
process.roles=broker
node.id=101
controller.quorum.voters=1@controller1:9093,2@controller2:9093,3@controller3:9093
listeners=PLAINTEXT://broker1:9092
advertised.listeners=PLAINTEXT://broker1:9092
log.dirs=/data/kraft-broker-logs

# æ··åˆæ¨¡å¼é…ç½®ï¼ˆæ§åˆ¶å™¨+æ•°æ®èŠ‚ç‚¹ï¼‰
process.roles=controller,broker
node.id=1
controller.quorum.voters=1@node1:9093,2@node2:9093,3@node3:9093
listeners=PLAINTEXT://node1:9092,CONTROLLER://node1:9093
advertised.listeners=PLAINTEXT://node1:9092
controller.listener.names=CONTROLLER
log.dirs=/data/kraft-combined-logs
```

### 2. æ–°ä¸€ä»£æ¶ˆè´¹è€…é‡å¹³è¡¡åè®®

#### 2.1 åè®®ä¼˜åŒ–ç‰¹æ€§
```java
// Kafka 4.0 æ–°ä¸€ä»£æ¶ˆè´¹è€…é…ç½®
Properties props = new Properties();
props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "kafka1:9092,kafka2:9092,kafka3:9092");
props.put(ConsumerConfig.GROUP_ID_CONFIG, "advanced-consumer-group");

// å¯ç”¨æ–°ä¸€ä»£é‡å¹³è¡¡åè®®
props.put(ConsumerConfig.GROUP_PROTOCOL_CONFIG, "consumer");

// ä¼˜åŒ–çš„åˆ†åŒºåˆ†é…ç­–ç•¥
props.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, 
    "org.apache.kafka.clients.consumer.CooperativeStickyAssignor");

// å¢é‡é‡å¹³è¡¡é…ç½®
props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 45000);
props.put(ConsumerConfig.HEARTBEAT_INTERVAL_MS_CONFIG, 3000);
props.put(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG, 300000);

// æ–°çš„æ¶ˆè´¹è€…å®ä¾‹
KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);
```

#### 2.2 å¢é‡é‡å¹³è¡¡æœºåˆ¶
```java
// å¢é‡é‡å¹³è¡¡ç›‘å¬å™¨
public class IncrementalRebalanceListener implements ConsumerRebalanceListener {
    
    @Override
    public void onPartitionsRevoked(Collection<TopicPartition> partitions) {
        // åªå¤„ç†è¢«æ’¤é”€çš„åˆ†åŒºï¼Œè€Œä¸æ˜¯å…¨éƒ¨åˆ†åŒº
        System.out.println("Incrementally revoked partitions: " + partitions);
        // æäº¤å½“å‰åç§»é‡
        consumer.commitSync();
    }
    
    @Override
    public void onPartitionsAssigned(Collection<TopicPartition> partitions) {
        // åªå¤„ç†æ–°åˆ†é…çš„åˆ†åŒº
        System.out.println("Incrementally assigned partitions: " + partitions);
        // æ¢å¤æ¶ˆè´¹ä½ç½®
        for (TopicPartition partition : partitions) {
            consumer.seek(partition, getStoredOffset(partition));
        }
    }
    
    @Override
    public void onPartitionsLost(Collection<TopicPartition> partitions) {
        // Kafka 4.0 æ–°å¢ï¼šå¤„ç†åˆ†åŒºä¸¢å¤±æƒ…å†µ
        System.out.println("Lost partitions: " + partitions);
        // æ¸…ç†æœ¬åœ°çŠ¶æ€
        cleanupLocalState(partitions);
    }
}
```

### 3. Queues for Kafkaï¼ˆé˜Ÿåˆ—æ¨¡å¼ï¼‰

#### 3.1 é˜Ÿåˆ—æ¨¡å¼é…ç½®
```properties
# Topicé…ç½®ä¸ºé˜Ÿåˆ—æ¨¡å¼
# åˆ›å»ºé˜Ÿåˆ—ç±»å‹çš„Topic
bin/kafka-topics.sh --bootstrap-server kafka1:9092 \
  --create --topic order-queue \
  --partitions 1 \
  --replication-factor 3 \
  --config "queue.mode=true" \
  --config "queue.delivery.semantic=exactly-once"

# é˜Ÿåˆ—æ¨¡å¼ç‰¹æ€§
queue_features:
  - ä¸¥æ ¼é¡ºåºï¼šæ¶ˆæ¯æŒ‰FIFOé¡ºåºå¤„ç†
  - å•æ¬¡æ¶ˆè´¹ï¼šæ¯æ¡æ¶ˆæ¯åªè¢«ä¸€ä¸ªæ¶ˆè´¹è€…å¤„ç†
  - è‡ªåŠ¨ç¡®è®¤ï¼šæ¶ˆè´¹æˆåŠŸåè‡ªåŠ¨æäº¤åç§»é‡
  - æ­»ä¿¡é˜Ÿåˆ—ï¼šå¤„ç†å¤±è´¥çš„æ¶ˆæ¯è‡ªåŠ¨è½¬å…¥DLQ
```

#### 3.2 é˜Ÿåˆ—æ¨¡å¼ç”Ÿäº§è€…
```java
// Kafka 4.0 é˜Ÿåˆ—æ¨¡å¼ç”Ÿäº§è€…
Properties producerProps = new Properties();
producerProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "kafka1:9092");
producerProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
producerProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);

// å¯ç”¨é˜Ÿåˆ—æ¨¡å¼
producerProps.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true);
producerProps.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, "queue-producer-1");

KafkaProducer<String, String> producer = new KafkaProducer<>(producerProps);

// åˆå§‹åŒ–äº‹åŠ¡
producer.initTransactions();

// å‘é€æ¶ˆæ¯åˆ°é˜Ÿåˆ—
producer.beginTransaction();
try {
    ProducerRecord<String, String> record = new ProducerRecord<>("order-queue", "order-123", orderJson);
    producer.send(record);
    producer.commitTransaction();
} catch (Exception e) {
    producer.abortTransaction();
    throw e;
}
```

---

## ğŸ“‹ Kafka 4.0é›†ç¾¤ç®¡ç†

### 1. KRafté›†ç¾¤éƒ¨ç½²å®æˆ˜

#### 1.1 é›†ç¾¤åˆå§‹åŒ–
```bash
# 1. ç”Ÿæˆé›†ç¾¤UUID
KAFKA_CLUSTER_ID=$(bin/kafka-storage.sh random-uuid)
echo "Cluster ID: $KAFKA_CLUSTER_ID"

# 2. æ ¼å¼åŒ–æ§åˆ¶å™¨èŠ‚ç‚¹å­˜å‚¨
bin/kafka-storage.sh format \
  -t $KAFKA_CLUSTER_ID \
  -c config/kraft-controller.properties

# 3. æ ¼å¼åŒ–æ•°æ®èŠ‚ç‚¹å­˜å‚¨
bin/kafka-storage.sh format \
  -t $KAFKA_CLUSTER_ID \
  -c config/kraft-broker.properties

# 4. å¯åŠ¨æ§åˆ¶å™¨èŠ‚ç‚¹
bin/kafka-server-start.sh config/kraft-controller.properties

# 5. å¯åŠ¨æ•°æ®èŠ‚ç‚¹
bin/kafka-server-start.sh config/kraft-broker.properties

# 6. éªŒè¯é›†ç¾¤çŠ¶æ€
bin/kafka-metadata-shell.sh --snapshot /data/kraft-controller-logs/__cluster_metadata-0/00000000000000000000.log
```

#### 1.2 é›†ç¾¤å¥åº·æ£€æŸ¥
```bash
# KRafté›†ç¾¤å¥åº·æ£€æŸ¥è„šæœ¬
#!/bin/bash
echo "=== Kafka 4.0 KRafté›†ç¾¤å¥åº·æ£€æŸ¥ ==="

# æ£€æŸ¥æ§åˆ¶å™¨çŠ¶æ€
echo "1. æ£€æŸ¥æ§åˆ¶å™¨çŠ¶æ€"
bin/kafka-metadata-shell.sh --snapshot /data/kraft-controller-logs/__cluster_metadata-0/00000000000000000000.log \
  --print-brokers

# æ£€æŸ¥é›†ç¾¤å…ƒæ•°æ®
echo "2. æ£€æŸ¥é›†ç¾¤å…ƒæ•°æ®"
bin/kafka-cluster.sh --bootstrap-server kafka1:9092 cluster-id
bin/kafka-cluster.sh --bootstrap-server kafka1:9092 describe

# æ£€æŸ¥TopicçŠ¶æ€
echo "3. æ£€æŸ¥TopicçŠ¶æ€"
bin/kafka-topics.sh --bootstrap-server kafka1:9092 --list
bin/kafka-topics.sh --bootstrap-server kafka1:9092 --describe --under-replicated-partitions

# æ£€æŸ¥æ¶ˆè´¹è€…ç»„çŠ¶æ€
echo "4. æ£€æŸ¥æ¶ˆè´¹è€…ç»„çŠ¶æ€"
bin/kafka-consumer-groups.sh --bootstrap-server kafka1:9092 --list

# æ£€æŸ¥æ€§èƒ½æŒ‡æ ‡
echo "5. æ£€æŸ¥æ€§èƒ½æŒ‡æ ‡"
bin/kafka-run-class.sh kafka.tools.JmxTool \
  --object-name kafka.controller:type=KafkaController,name=ActiveControllerCount \
  --jmx-url service:jmx:rmi:///jndi/rmi://kafka1:9999/jmxrmi
```

### 2. Kafka 4.0é›†ç¾¤æ‰©å®¹

#### 2.1 åŠ¨æ€æ‰©å®¹æµç¨‹
```bash
# 1. å‡†å¤‡æ–°çš„æ•°æ®èŠ‚ç‚¹
# é…ç½®kraft-broker-new.properties
process.roles=broker
node.id=104  # æ–°çš„èŠ‚ç‚¹ID
controller.quorum.voters=1@controller1:9093,2@controller2:9093,3@controller3:9093
listeners=PLAINTEXT://broker4:9092
advertised.listeners=PLAINTEXT://broker4:9092
log.dirs=/data/kraft-broker-logs-4

# 2. æ ¼å¼åŒ–æ–°èŠ‚ç‚¹å­˜å‚¨
bin/kafka-storage.sh format \
  -t $KAFKA_CLUSTER_ID \
  -c config/kraft-broker-new.properties

# 3. å¯åŠ¨æ–°èŠ‚ç‚¹
bin/kafka-server-start.sh config/kraft-broker-new.properties

# 4. éªŒè¯æ–°èŠ‚ç‚¹åŠ å…¥
bin/kafka-cluster.sh --bootstrap-server kafka1:9092 describe

# 5. åˆ›å»ºæ™ºèƒ½åˆ†åŒºé‡åˆ†é…è®¡åˆ’
echo '{
  "topics": [
    {"topic": "user-events"},
    {"topic": "order-events"},
    {"topic": "payment-events"}
  ],
  "version": 1
}' > topics-to-move.json

# 6. ç”Ÿæˆé‡åˆ†é…è®¡åˆ’
bin/kafka-reassign-partitions.sh \
  --bootstrap-server kafka1:9092 \
  --topics-to-move-json-file topics-to-move.json \
  --broker-list "101,102,103,104" \
  --generate > reassignment-plan.json

# 7. æ‰§è¡Œå¢é‡é‡åˆ†é…
bin/kafka-reassign-partitions.sh \
  --bootstrap-server kafka1:9092 \
  --reassignment-json-file reassignment-plan.json \
  --execute \
  --throttle 50000000  # 50MB/sé™æµ

# 8. ç›‘æ§é‡åˆ†é…è¿›åº¦
bin/kafka-reassign-partitions.sh \
  --bootstrap-server kafka1:9092 \
  --reassignment-json-file reassignment-plan.json \
  --verify
```

#### 2.2 æ™ºèƒ½è´Ÿè½½å‡è¡¡
```python
# Kafka 4.0 æ™ºèƒ½è´Ÿè½½å‡è¡¡ç®—æ³•
class KafkaLoadBalancer:
    def __init__(self, cluster_info):
        self.cluster_info = cluster_info
        self.target_imbalance_threshold = 0.1  # 10%ä¸å¹³è¡¡é˜ˆå€¼
    
    def calculate_optimal_assignment(self):
        """
        åŸºäºæœºå™¨å­¦ä¹ çš„åˆ†åŒºåˆ†é…ä¼˜åŒ–
        """
        brokers = self.cluster_info['brokers']
        topics = self.cluster_info['topics']
        
        # è®¡ç®—æ¯ä¸ªbrokerçš„è´Ÿè½½æƒé‡
        broker_weights = {}
        for broker in brokers:
            cpu_weight = 1.0 - broker['cpu_usage']
            memory_weight = 1.0 - broker['memory_usage']
            disk_weight = 1.0 - broker['disk_usage']
            network_weight = 1.0 - broker['network_usage']
            
            # ç»¼åˆæƒé‡è®¡ç®—
            broker_weights[broker['id']] = (
                cpu_weight * 0.3 + 
                memory_weight * 0.2 + 
                disk_weight * 0.3 + 
                network_weight * 0.2
            )
        
        # åŸºäºæƒé‡çš„åˆ†åŒºåˆ†é…
        assignment = self.weighted_round_robin_assignment(
            topics, broker_weights
        )
        
        return assignment
    
    def weighted_round_robin_assignment(self, topics, weights):
        """
        åŠ æƒè½®è¯¢åˆ†åŒºåˆ†é…ç®—æ³•
        """
        assignment = {}
        
        for topic in topics:
            partitions = topic['partitions']
            replicas = topic['replication_factor']
            
            # æŒ‰æƒé‡æ’åºbroker
            sorted_brokers = sorted(
                weights.items(), 
                key=lambda x: x[1], 
                reverse=True
            )
            
            topic_assignment = []
            for partition_id in range(partitions):
                partition_replicas = []
                
                # ä¸ºæ¯ä¸ªåˆ†åŒºé€‰æ‹©å‰¯æœ¬broker
                for replica_id in range(replicas):
                    broker_idx = (partition_id + replica_id) % len(sorted_brokers)
                    broker_id = sorted_brokers[broker_idx][0]
                    partition_replicas.append(broker_id)
                
                topic_assignment.append(partition_replicas)
            
            assignment[topic['name']] = topic_assignment
        
        return assignment
```

### 3. Kafka 4.0æ•°æ®è¿ç§»

#### 3.1 è·¨ç‰ˆæœ¬è¿ç§»ç­–ç•¥
```bash
# ä»Kafka 3.xè¿ç§»åˆ°4.0çš„å®Œæ•´æµç¨‹

# 1. è¿ç§»å‰å‡†å¤‡
echo "=== Kafka 3.x to 4.0 è¿ç§»å‡†å¤‡ ==="

# å¤‡ä»½Zookeeperæ•°æ®
bin/zookeeper-shell.sh zk1:2181 <<< "ls /brokers/ids" > broker-backup.txt
bin/zookeeper-shell.sh zk1:2181 <<< "ls /config/topics" > topics-backup.txt

# å¯¼å‡ºTopicé…ç½®
bin/kafka-configs.sh --bootstrap-server kafka1:9092 \
  --entity-type topics --describe --all > topic-configs-backup.txt

# 2. è®¾ç½®KRafté›†ç¾¤
echo "=== è®¾ç½®KRafté›†ç¾¤ ==="

# ç”Ÿæˆæ–°çš„é›†ç¾¤ID
KRAFT_CLUSTER_ID=$(bin/kafka-storage.sh random-uuid)

# é…ç½®KRaftæ§åˆ¶å™¨
cat > kraft-migration-controller.properties << EOF
process.roles=controller
node.id=1
controller.quorum.voters=1@kraft-controller1:9093,2@kraft-controller2:9093,3@kraft-controller3:9093
listeners=CONTROLLER://kraft-controller1:9093
controller.listener.names=CONTROLLER
log.dirs=/data/kraft-migration-controller
EOF

# 3. æ‰§è¡Œåœ¨çº¿è¿ç§»
echo "=== æ‰§è¡Œåœ¨çº¿è¿ç§» ==="

# å¯ç”¨è¿ç§»æ¨¡å¼
bin/kafka-storage.sh format \
  -t $KRAFT_CLUSTER_ID \
  -c kraft-migration-controller.properties \
  --add-scram SCRAM-SHA-256=[name=admin,password=admin-secret]

# å¯åŠ¨KRaftæ§åˆ¶å™¨
bin/kafka-server-start.sh kraft-migration-controller.properties &

# é…ç½®ç°æœ‰brokerè¿›å…¥è¿ç§»æ¨¡å¼
echo "zookeeper.metadata.migration.enable=true" >> config/server.properties
echo "controller.quorum.voters=1@kraft-controller1:9093,2@kraft-controller2:9093,3@kraft-controller3:9093" >> config/server.properties

# é‡å¯ç°æœ‰broker
bin/kafka-server-stop.sh
bin/kafka-server-start.sh config/server.properties &

# 4. éªŒè¯è¿ç§»çŠ¶æ€
echo "=== éªŒè¯è¿ç§»çŠ¶æ€ ==="

# æ£€æŸ¥è¿ç§»è¿›åº¦
bin/kafka-metadata-shell.sh --snapshot /data/kraft-migration-controller/__cluster_metadata-0/00000000000000000000.log \
  --print-brokers

# éªŒè¯Topicå’Œæ•°æ®å®Œæ•´æ€§
bin/kafka-topics.sh --bootstrap-server kafka1:9092 --list
bin/kafka-console-consumer.sh --bootstrap-server kafka1:9092 \
  --topic test-topic --from-beginning --max-messages 10

# 5. å®Œæˆè¿ç§»
echo "=== å®Œæˆè¿ç§» ==="

# ç§»é™¤Zookeeperä¾èµ–
sed -i '/zookeeper.connect/d' config/server.properties
sed -i '/zookeeper.metadata.migration.enable/d' config/server.properties

# é‡å¯brokerå®Œæˆè¿ç§»
bin/kafka-server-stop.sh
bin/kafka-server-start.sh config/server.properties &

echo "Kafka 4.0 KRaftè¿ç§»å®Œæˆï¼"
```

#### 3.2 é›¶åœæœºè¿ç§»å·¥å…·
```java
// Kafka 4.0 é›¶åœæœºè¿ç§»å·¥å…·
public class ZeroDowntimeMigrationTool {
    
    private final AdminClient sourceAdmin;
    private final AdminClient targetAdmin;
    private final Map<String, Object> migrationConfig;
    
    public ZeroDowntimeMigrationTool(String sourceBootstrap, String targetBootstrap) {
        this.sourceAdmin = AdminClient.create(Map.of(
            AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, sourceBootstrap
        ));
        this.targetAdmin = AdminClient.create(Map.of(
            AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, targetBootstrap
        ));
        this.migrationConfig = loadMigrationConfig();
    }
    
    public void executeMigration() throws Exception {
        // 1. åˆ†ææºé›†ç¾¤
        ClusterAnalysis sourceAnalysis = analyzeSourceCluster();
        
        // 2. åˆ›å»ºç›®æ ‡Topicç»“æ„
        createTargetTopics(sourceAnalysis.getTopics());
        
        // 3. å¯åŠ¨æ•°æ®åŒæ­¥
        MirrorMaker2Config mm2Config = createMM2Config();
        startMirrorMaker2(mm2Config);
        
        // 4. ç›‘æ§åŒæ­¥è¿›åº¦
        monitorSyncProgress();
        
        // 5. æ‰§è¡Œæµé‡åˆ‡æ¢
        performTrafficSwitch();
        
        // 6. éªŒè¯è¿ç§»ç»“æœ
        validateMigration();
    }
    
    private void createTargetTopics(List<TopicDescription> sourceTopics) {
        for (TopicDescription topic : sourceTopics) {
            NewTopic newTopic = new NewTopic(
                topic.name(),
                topic.partitions().size(),
                (short) topic.partitions().get(0).replicas().size()
            );
            
            // å¤åˆ¶Topicé…ç½®
            Map<String, String> configs = getTopicConfigs(topic.name());
            newTopic.configs(configs);
            
            targetAdmin.createTopics(Collections.singleton(newTopic));
        }
    }
    
    private void performTrafficSwitch() {
        // å®ç°æ¸è¿›å¼æµé‡åˆ‡æ¢
        TrafficSwitcher switcher = new TrafficSwitcher();
        
        // 10% -> 50% -> 100% æ¸è¿›åˆ‡æ¢
        switcher.switchTraffic(0.1);
        Thread.sleep(60000); // ç­‰å¾…1åˆ†é’Ÿè§‚å¯Ÿ
        
        switcher.switchTraffic(0.5);
        Thread.sleep(300000); // ç­‰å¾…5åˆ†é’Ÿè§‚å¯Ÿ
        
        switcher.switchTraffic(1.0);
        System.out.println("æµé‡åˆ‡æ¢å®Œæˆ");
    }
}
```

### 4. Kafka 4.0ç›‘æ§å’Œæ•…éšœæ’æŸ¥

#### 4.1 KRaftæ¨¡å¼ç›‘æ§
```yaml
# Kafka 4.0 KRaftç›‘æ§é…ç½®
kraft_monitoring:
  controller_metrics:
    - kafka.controller:type=KafkaController,name=ActiveControllerCount
    - kafka.controller:type=ControllerStats,name=LeaderElectionRateAndTimeMs
    - kafka.controller:type=ControllerStats,name=UncleanLeaderElectionsPerSec
    - kafka.server:type=KafkaServer,name=BrokerState
    
  metadata_metrics:
    - kafka.server:type=MetadataLoader,name=MetadataLoadErrorCount
    - kafka.server:type=MetadataLoader,name=MetadataApplyErrorCount
    - kafka.server:type=BrokerMetadata,name=MetadataCount
    
  raft_metrics:
    - kafka.raft:type=KafkaRaftServer,name=CurrentLeader
    - kafka.raft:type=KafkaRaftServer,name=CurrentEpoch
    - kafka.raft:type=KafkaRaftServer,name=HighWatermark
    
  queue_metrics:  # Kafka 4.0 é˜Ÿåˆ—æ¨¡å¼ç›‘æ§
    - kafka.server:type=QueueMetrics,name=QueueSize
    - kafka.server:type=QueueMetrics,name=DeadLetterQueueSize
    - kafka.server:type=QueueMetrics,name=ProcessingRate
```

#### 4.2 é«˜çº§æ•…éšœæ’æŸ¥å·¥å…·
```bash
# Kafka 4.0 æ•…éšœæ’æŸ¥å·¥å…·é›†

# 1. KRafté›†ç¾¤è¯Šæ–­å·¥å…·
#!/bin/bash
kraft_cluster_diagnosis() {
    echo "=== Kafka 4.0 KRafté›†ç¾¤è¯Šæ–­ ==="
    
    # æ£€æŸ¥æ§åˆ¶å™¨çŠ¶æ€
    echo "1. æ§åˆ¶å™¨çŠ¶æ€æ£€æŸ¥"
    bin/kafka-metadata-shell.sh --snapshot /data/kraft-controller-logs/__cluster_metadata-0/00000000000000000000.log \
      --print-controllers
    
    # æ£€æŸ¥Raftæ—¥å¿—
    echo "2. Raftæ—¥å¿—æ£€æŸ¥"
    bin/kafka-dump-log.sh --files /data/kraft-controller-logs/__cluster_metadata-0/00000000000000000000.log \
      --print-data-log
    
    # æ£€æŸ¥å…ƒæ•°æ®ä¸€è‡´æ€§
    echo "3. å…ƒæ•°æ®ä¸€è‡´æ€§æ£€æŸ¥"
    for controller in controller1 controller2 controller3; do
        echo "æ£€æŸ¥æ§åˆ¶å™¨: $controller"
        bin/kafka-metadata-shell.sh --snapshot /data/kraft-controller-logs/__cluster_metadata-0/00000000000000000000.log \
          --print-brokers | grep -c "broker"
    done
    
    # æ£€æŸ¥åˆ†åŒºçŠ¶æ€
    echo "4. åˆ†åŒºçŠ¶æ€æ£€æŸ¥"
    bin/kafka-topics.sh --bootstrap-server kafka1:9092 \
      --describe --under-replicated-partitions
    
    # æ£€æŸ¥æ¶ˆè´¹è€…ç»„æ–°åè®®
    echo "5. æ¶ˆè´¹è€…ç»„åè®®æ£€æŸ¥"
    bin/kafka-consumer-groups.sh --bootstrap-server kafka1:9092 \
      --describe --all-groups --verbose
}

# 2. æ€§èƒ½åˆ†æå·¥å…·
performance_analysis() {
    echo "=== Kafka 4.0 æ€§èƒ½åˆ†æ ==="
    
    # æµ‹è¯•æ–°ä¸€ä»£æ¶ˆè´¹è€…æ€§èƒ½
    echo "1. æ–°ä¸€ä»£æ¶ˆè´¹è€…æ€§èƒ½æµ‹è¯•"
    bin/kafka-consumer-perf-test.sh \
      --bootstrap-server kafka1:9092 \
      --topic perf-test \
      --messages 1000000 \
      --consumer-config consumer.properties
    
    # æµ‹è¯•é˜Ÿåˆ—æ¨¡å¼æ€§èƒ½
    echo "2. é˜Ÿåˆ—æ¨¡å¼æ€§èƒ½æµ‹è¯•"
    bin/kafka-producer-perf-test.sh \
      --topic order-queue \
      --num-records 100000 \
      --record-size 1024 \
      --throughput 10000 \
      --producer-props bootstrap.servers=kafka1:9092,enable.idempotence=true
    
    # JVMæ€§èƒ½åˆ†æ
    echo "3. JVMæ€§èƒ½åˆ†æ"
    jstat -gc -t $(pgrep -f kafka.Kafka) 5s 10
    
    # ç½‘ç»œæ€§èƒ½åˆ†æ
    echo "4. ç½‘ç»œæ€§èƒ½åˆ†æ"
    iftop -i eth0 -t -s 10
}

# 3. è‡ªåŠ¨æ•…éšœæ¢å¤
auto_recovery() {
    echo "=== Kafka 4.0 è‡ªåŠ¨æ•…éšœæ¢å¤ ==="
    
    # æ£€æµ‹æ§åˆ¶å™¨æ•…éšœ
    if ! bin/kafka-metadata-shell.sh --snapshot /data/kraft-controller-logs/__cluster_metadata-0/00000000000000000000.log --print-controllers | grep -q "ACTIVE"; then
        echo "æ£€æµ‹åˆ°æ§åˆ¶å™¨æ•…éšœï¼Œå¯åŠ¨æ¢å¤ç¨‹åº"
        
        # é‡å¯æ§åˆ¶å™¨
        systemctl restart kafka-controller
        
        # ç­‰å¾…é€‰ä¸¾å®Œæˆ
        sleep 30
        
        # éªŒè¯æ¢å¤çŠ¶æ€
        bin/kafka-cluster.sh --bootstrap-server kafka1:9092 describe
    fi
    
    # æ£€æµ‹æ•°æ®èŠ‚ç‚¹æ•…éšœ
    failed_brokers=$(bin/kafka-topics.sh --bootstrap-server kafka1:9092 --describe --under-replicated-partitions | wc -l)
    if [ $failed_brokers -gt 0 ]; then
        echo "æ£€æµ‹åˆ°æ•°æ®èŠ‚ç‚¹æ•…éšœï¼Œå¯åŠ¨åˆ†åŒºé‡åˆ†é…"
        
        # è‡ªåŠ¨ç”Ÿæˆé‡åˆ†é…è®¡åˆ’
        bin/kafka-reassign-partitions.sh \
          --bootstrap-server kafka1:9092 \
          --generate \
          --topics-to-move-json-file failed-topics.json \
          --broker-list "$(get_healthy_brokers)"
    fi
}
```

---

## ğŸ› ï¸ å®è·µä»»åŠ¡

### ä»»åŠ¡1ï¼šé›†ç¾¤æ‰©å®¹å®æˆ˜
1. æ­å»º3èŠ‚ç‚¹Kafkaé›†ç¾¤
2. åˆ›å»ºæµ‹è¯•Topicå¹¶å†™å…¥æ•°æ®
3. æ·»åŠ ç¬¬4ä¸ªèŠ‚ç‚¹
4. æ‰§è¡Œåˆ†åŒºé‡åˆ†é…
5. éªŒè¯æ•°æ®å®Œæ•´æ€§

### ä»»åŠ¡2ï¼šæ•°æ®è¿ç§»æ¼”ç»ƒ
1. è®¾ç½®æºé›†ç¾¤å’Œç›®æ ‡é›†ç¾¤
2. é…ç½®MirrorMaker 2.0
3. æ‰§è¡Œæ•°æ®åŒæ­¥
4. éªŒè¯åŒæ­¥æ•ˆæœ
5. å®ç°æ•…éšœåˆ‡æ¢

### ä»»åŠ¡3ï¼šç‰ˆæœ¬å‡çº§å®è·µ
1. ä»Kafka 2.8å‡çº§åˆ°3.6
2. æ‰§è¡Œæ»šåŠ¨å‡çº§
3. éªŒè¯å‡çº§ååŠŸèƒ½
4. æ€§èƒ½å¯¹æ¯”æµ‹è¯•

### ä»»åŠ¡4ï¼šç›‘æ§ç³»ç»Ÿæ­å»º
1. éƒ¨ç½²Prometheus + Grafana
2. é…ç½®Kafka JMXç›‘æ§
3. åˆ›å»ºå‘Šè­¦è§„åˆ™
4. æ¨¡æ‹Ÿæ•…éšœåœºæ™¯

---

## ğŸ“Š æŠ€èƒ½éªŒæ”¶æ ‡å‡†

### åŸºç¡€è¦æ±‚ï¼ˆ60åˆ†ï¼‰
- [ ] èƒ½å¤Ÿç‹¬ç«‹éƒ¨ç½²3èŠ‚ç‚¹Kafkaé›†ç¾¤
- [ ] æŒæ¡åŸºæœ¬çš„é›†ç¾¤æ‰©å®¹æ“ä½œ
- [ ] äº†è§£æ•°æ®å¤‡ä»½å’Œæ¢å¤æµç¨‹
- [ ] èƒ½å¤Ÿæ‰§è¡Œç®€å•çš„ç‰ˆæœ¬å‡çº§

### è¿›é˜¶è¦æ±‚ï¼ˆ80åˆ†ï¼‰
- [ ] èƒ½å¤Ÿè®¾è®¡é«˜å¯ç”¨é›†ç¾¤æ¶æ„
- [ ] æŒæ¡è·¨é›†ç¾¤æ•°æ®è¿ç§»æŠ€æœ¯
- [ ] èƒ½å¤Ÿå¤„ç†å¤æ‚çš„æ•…éšœåœºæ™¯
- [ ] æŒæ¡æ€§èƒ½è°ƒä¼˜å’Œç›‘æ§

### ä¸“å®¶è¦æ±‚ï¼ˆ100åˆ†ï¼‰
- [ ] èƒ½å¤Ÿè®¾è®¡å¤šæ•°æ®ä¸­å¿ƒæ¶æ„
- [ ] æŒæ¡è‡ªåŠ¨åŒ–è¿ç»´è„šæœ¬å¼€å‘
- [ ] èƒ½å¤Ÿå¤„ç†å¤§è§„æ¨¡é›†ç¾¤ç®¡ç†
- [ ] å…·å¤‡ç¾éš¾æ¢å¤æ–¹æ¡ˆè®¾è®¡èƒ½åŠ›

---

## ğŸ“š å­¦ä¹ èµ„æº

### å®˜æ–¹æ–‡æ¡£
- [Kafka Operations Guide](https://kafka.apache.org/documentation/#operations)
- [Kafka Upgrade Guide](https://kafka.apache.org/documentation/#upgrade)

### æ¨èå·¥å…·
- **Kafka Manager**: Webç•Œé¢ç®¡ç†å·¥å…·
- **Cruise Control**: LinkedInå¼€æºçš„Kafkaé›†ç¾¤ç®¡ç†å·¥å…·
- **Strimzi**: Kubernetesä¸Šçš„Kafka Operator
- **Confluent Control Center**: ä¼ä¸šçº§ç®¡ç†å¹³å°

### ç›‘æ§æ–¹æ¡ˆ
- **JMX + Prometheus + Grafana**: å¼€æºç›‘æ§æ ˆ
- **Confluent Control Center**: å•†ä¸šç›‘æ§æ–¹æ¡ˆ
- **Datadog**: SaaSç›‘æ§æœåŠ¡

---

## ğŸ¯ é¢è¯•è¦ç‚¹

### é«˜é¢‘é—®é¢˜
1. **å¦‚ä½•è®¾è®¡ä¸€ä¸ªé«˜å¯ç”¨çš„Kafkaé›†ç¾¤ï¼Ÿ**
   - å¤šå‰¯æœ¬é…ç½®
   - æœºæ¶æ„ŸçŸ¥
   - è·¨æ•°æ®ä¸­å¿ƒéƒ¨ç½²

2. **Kafkaé›†ç¾¤æ‰©å®¹æ—¶å¦‚ä½•ä¿è¯æ•°æ®ä¸ä¸¢å¤±ï¼Ÿ**
   - åˆ†åŒºé‡åˆ†é…æœºåˆ¶
   - å‰¯æœ¬åŒæ­¥ç¡®è®¤
   - ç›‘æ§under-replicatedåˆ†åŒº

3. **å¦‚ä½•å¤„ç†Kafkaé›†ç¾¤çš„è„‘è£‚é—®é¢˜ï¼Ÿ**
   - min.insync.replicasé…ç½®
   - unclean.leader.election.enable=false
   - ç›‘æ§ControllerçŠ¶æ€

4. **Kafkaç‰ˆæœ¬å‡çº§çš„æœ€ä½³å®è·µæ˜¯ä»€ä¹ˆï¼Ÿ**
   - æ»šåŠ¨å‡çº§ç­–ç•¥
   - å…¼å®¹æ€§é…ç½®
   - å‡çº§éªŒè¯æµç¨‹

### å®æˆ˜åœºæ™¯é¢˜
1. **ç”Ÿäº§ç¯å¢ƒä¸­æŸä¸ªBrokerçªç„¶å®•æœºï¼Œå¦‚ä½•å¿«é€Ÿæ¢å¤ï¼Ÿ**
2. **å¦‚ä½•å®ç°Kafkaé›†ç¾¤çš„é›¶åœæœºç»´æŠ¤ï¼Ÿ**
3. **å¤§è§„æ¨¡æ•°æ®è¿ç§»æ—¶å¦‚ä½•ä¿è¯æ€§èƒ½ï¼Ÿ**
4. **å¦‚ä½•è®¾è®¡Kafkaçš„ç¾éš¾æ¢å¤æ–¹æ¡ˆï¼Ÿ**

---

## ğŸ’¡ æœ€ä½³å®è·µæ€»ç»“

1. **é›†ç¾¤è§„åˆ’**ï¼šåˆç†è§„åˆ’é›†ç¾¤è§„æ¨¡ï¼Œè€ƒè™‘æœªæ¥æ‰©å±•éœ€æ±‚
2. **ç›‘æ§å…ˆè¡Œ**ï¼šå®Œå–„çš„ç›‘æ§ä½“ç³»æ˜¯è¿ç»´çš„åŸºç¡€
3. **è‡ªåŠ¨åŒ–è¿ç»´**ï¼šå‡å°‘äººå·¥æ“ä½œï¼Œæé«˜è¿ç»´æ•ˆç‡
4. **å®šæœŸæ¼”ç»ƒ**ï¼šå®šæœŸè¿›è¡Œæ•…éšœæ¼”ç»ƒå’Œæ¢å¤æµ‹è¯•
5. **æ–‡æ¡£ç®¡ç†**ï¼šç»´æŠ¤è¯¦ç»†çš„è¿ç»´æ–‡æ¡£å’Œæ“ä½œæ‰‹å†Œ

é€šè¿‡ç¬¬6å¤©çš„å­¦ä¹ ï¼Œä½ å°†å…·å¤‡Kafkaé›†ç¾¤ç®¡ç†å’Œç»´æŠ¤çš„æ ¸å¿ƒæŠ€èƒ½ï¼Œèƒ½å¤Ÿåœ¨ç”Ÿäº§ç¯å¢ƒä¸­ç‹¬ç«‹å¤„ç†å„ç§è¿ç»´åœºæ™¯ï¼